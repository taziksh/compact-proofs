{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0f29ec1-dece-44fe-bd0f-785c0fe5d536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import random\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from fancy_einsum import einsum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "d_vocab = 64\n",
    "d = d_head = d_model = 32\n",
    "n_ctx = k = 4\n",
    "batch_size = 128 #TODO: use batch size 128\n",
    "\n",
    "#Global seed\n",
    "global_seed = 123\n",
    "torch.manual_seed(global_seed)\n",
    "np.random.seed(global_seed)\n",
    "random.seed(global_seed)\n",
    "\n",
    "\n",
    "def plot_heatmap(matrix, title, xlabel, ylabel):\n",
    "    if matrix.dim() == 3:  # Assuming shape (batch_size, n_ctx, n_ctx)\n",
    "        matrix = matrix.mean(dim=0)  # Average over batch size\n",
    "\n",
    "    # Convert tensor to numpy array if it's not already\n",
    "    if hasattr(matrix, 'detach'):\n",
    "        matrix = matrix.detach().numpy()\n",
    "        \n",
    "    # Create custom colormap\n",
    "    colors = ['darkred', 'red', 'orange', 'yellow', 'white', 'lightblue', 'blue', 'darkblue']\n",
    "    n_bins = 256  # Number of color gradations\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom\", colors, N=n_bins)\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    im = ax.imshow(matrix, cmap=cmap, aspect='auto', \n",
    "                    vmin=np.percentile(matrix, 1), vmax=np.percentile(matrix, 99))\n",
    "    \n",
    "    cbar = plt.colorbar(im)\n",
    "\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel(xlabel, fontsize=12)\n",
    "    ax.set_ylabel(ylabel, fontsize=12)\n",
    "    ax.grid(which='major', color='w', linestyle='-', linewidth=0.5)\n",
    "\n",
    "    return fig\n",
    "\n",
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.E = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(batch_size, d_vocab, d_model)))\n",
    "        self.P = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(n_ctx, d_model)))\n",
    "        self.P_query = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(n_ctx, d_model)))\n",
    "\n",
    "        self.Q = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(d_model, d_model)))\n",
    "        self.K = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(d_model, d_model)))\n",
    "        self.V = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(d_model, d_model)))\n",
    "        self.O = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(d_model, d_model)))\n",
    "\n",
    "        self.U = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty(d_model, d_vocab)))\n",
    "\n",
    "        self.EQKE = None\n",
    "        self.EQKP = None\n",
    "        self.EVOU = None\n",
    "        self.PVOU = None\n",
    "        self.EU = None\n",
    "\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # Note: dropping dim=0 ie batch dim\n",
    "        x = F.one_hot(input_ids, num_classes=d_vocab).float()\n",
    "        assert x.shape == (batch_size, n_ctx, d_vocab)\n",
    "\n",
    "        x_query = x[:, -1, :] # (batch_size, d_vocab)\n",
    "        assert x_query.shape == (batch_size, d_vocab)\n",
    "\n",
    "        # dim=-1 => summing across d_model dimension\n",
    "        #P_avg = torch.sum(self.P) / n_ctx   \n",
    "        P_avg = torch.mean(self.P, dim=0, keepdim=True)  # Average over context positions \n",
    "        # assert P_avg.numel() == 1\n",
    "\n",
    "        # breakpoint()\n",
    "\n",
    "        # Note: P_bar is broadcasted P_avg\n",
    "\n",
    "        # E_bar = E + P_bar\n",
    "        E_bar = self.E + P_avg.expand(d_vocab, d_model)\n",
    "        assert E_bar.shape == (batch_size, d_vocab, d_model)\n",
    "\n",
    "        # E_q = E + P_q\n",
    "        # Mean across n_ctx dim, to make it position independent\n",
    "        E_q = self.E + self.P_query.mean(dim=0, keepdim=True)\n",
    "        assert E_q.shape == (batch_size, d_vocab, d_model)\n",
    "\n",
    "\n",
    "        scaling_factor = 1 / math.sqrt(d_model)\n",
    "\n",
    "        # Position independent\n",
    "        self.EQKE = scaling_factor * (E_q @ self.Q @ self.K.T @ E_bar.transpose(1, 2))\n",
    "        # self.EQKE = E_q @ self.Q @ self.K.T @ E_bar.transpose(1, 2)\n",
    "\n",
    "\n",
    "        assert self.EQKE.shape == (batch_size, d_vocab, d_vocab)\n",
    "\n",
    "        # P_hat = P - P_bar\n",
    "        #P_hat = self.P - self.P_query\n",
    "        P_hat = self.P - P_avg\n",
    "        assert P_hat.shape == (n_ctx, d_model)\n",
    "\n",
    "        # Position dependent\n",
    "        self.EQKP = scaling_factor * (E_q @ self.Q @ self.K.T @ P_hat.T)\n",
    "        # self.EQKP = E_q @ self.Q @ self.K.T @ P_hat.T\n",
    "        assert self.EQKP.shape == (batch_size, d_vocab, n_ctx)   \n",
    "\n",
    "        # breakpoint()\n",
    "        QK = x_query @ (self.EQKE @ x.transpose(1, 2) + self.EQKP)\n",
    "        QK = einsum('batch d_vocab, batch d_vocab n_ctx -> batch d_vocab n_ctx', x_query, self.EQKE @ x.transpose(1, 2) + self.EQKP)\n",
    "        # assert QK.shape == (n_ctx, n_ctx)\n",
    "        assert QK.shape == (batch_size, d_vocab, n_ctx)\n",
    "\n",
    "        self.EVOU = E_bar @ self.V @ self.O @ self.U\n",
    "        self.PVOU = P_hat @ self.V @ self.O @ self.U\n",
    "        assert self.EVOU.shape == (batch_size, d_vocab, d_vocab)\n",
    "        assert self.PVOU.shape == (n_ctx, d_vocab)\n",
    "\n",
    "\n",
    "        OV = x @ self.EVOU + self.PVOU\n",
    "        assert OV.shape == (batch_size, n_ctx, d_vocab)\n",
    "\n",
    "        self.EU = (E_q @ self.U)\n",
    "        # assert self.direct_path.shape == (n_ctx, d_vocab)\n",
    "        direct_path = einsum('batch d_vocab, batch d_vocab d_vocab_2 -> batch d_vocab d_vocab_2', x_query, self.EU) # x_query @ self.EU\n",
    "        assert direct_path.shape == (batch_size, d_vocab, d_vocab)\n",
    "\n",
    "        # Apply causal attention mask\n",
    "        causal_mask = torch.tril(torch.ones(d_vocab, n_ctx)) # should i do batch_size, d_vocab, n_ctx\n",
    "        QK = QK.masked_fill(causal_mask == 0, float('-inf'))\n",
    "\n",
    "        #TODO dim=0, -1 are both n_ctx which do i sum over \n",
    "        M = torch.softmax(QK/scaling_factor, dim=-1) @ OV + direct_path\n",
    "        #assert M.shape == (n_ctx, d_vocab)\n",
    "        assert M.shape == (batch_size, d_vocab, d_vocab)\n",
    "\n",
    "        final_logits = M[:, -1, :]\n",
    "        # l_max = torch.argmax(final_logits)\n",
    "        return final_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18f9d071-6a86-41b5-84f8-4a30eb29ccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 0, Loss: 4.1691\n",
      "Epoch: 1, Step: 100, Loss: 4.0797\n",
      "Epoch: 1, Step: 200, Loss: 4.0128\n",
      "Epoch: 1, Step: 300, Loss: 4.0197\n",
      "Epoch: 1, Step: 400, Loss: 3.9585\n",
      "Epoch: 1, Step: 500, Loss: 3.8289\n",
      "Epoch: 1, Step: 600, Loss: 3.7962\n",
      "Epoch: 1, Step: 700, Loss: 3.7758\n",
      "Epoch: 1, Step: 800, Loss: 3.5091\n",
      "Epoch: 1, Step: 900, Loss: 3.5126\n",
      "Epoch: 1, Step: 1000, Loss: 3.3763\n",
      "Epoch: 1, Step: 1100, Loss: 3.2355\n",
      "Epoch: 1, Step: 1200, Loss: 3.4498\n",
      "Epoch: 1, Step: 1300, Loss: 3.2061\n",
      "Epoch: 1, Step: 1400, Loss: 3.1352\n",
      "Epoch: 1, Step: 1500, Loss: 3.0982\n",
      "Epoch: 1, Step: 1600, Loss: 3.0712\n",
      "Epoch: 1, Step: 1700, Loss: 2.9635\n",
      "Epoch: 1, Step: 1800, Loss: 3.0349\n",
      "Epoch: 1, Step: 1900, Loss: 3.1356\n",
      "Epoch: 1, Step: 2000, Loss: 3.0671\n",
      "Epoch: 1, Step: 2100, Loss: 3.0200\n",
      "Epoch: 1, Step: 2200, Loss: 3.2234\n",
      "Epoch: 1, Step: 2300, Loss: 3.0202\n",
      "Epoch: 1, Step: 2400, Loss: 2.9859\n",
      "Epoch: 1, Step: 2500, Loss: 3.2675\n",
      "Epoch: 1, Step: 2600, Loss: 3.0749\n",
      "Epoch: 1, Step: 2700, Loss: 3.0243\n",
      "Epoch: 1, Step: 2800, Loss: 2.8013\n",
      "Epoch: 1, Step: 2900, Loss: 2.9315\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Generate random sequences\n",
    "    num_sequences = 384000\n",
    "\n",
    "    sequences = torch.randint(0, d_vocab, (num_sequences, n_ctx))\n",
    "\n",
    "    dataset = TensorDataset(sequences)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model_seed = 613947648\n",
    "    torch.manual_seed(model_seed)\n",
    "    model = Transformer()\n",
    "    optimizer = AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=0.01)\n",
    "\n",
    "    num_epochs = 1\n",
    "    num_steps = num_sequences // batch_size\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for step, (batch,) in enumerate(dataloader):\n",
    "            if step >= num_steps:\n",
    "                break\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            input_ids = batch\n",
    "            logits = model(input_ids)\n",
    "\n",
    "            # Compute loss\n",
    "            targets = input_ids[:, -1]  # Last token in each sequence\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                print(f\"Epoch: {epoch+1}, Step: {step}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "359629d6-9b67-4bd5-9a60-e44a7d311d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(41.9723, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1311, -0.0763,  0.1654,  ...,  0.0015,  0.0286,  0.0662],\n",
       "         [-0.1190, -0.0061,  0.1447,  ...,  0.0337,  0.1095,  0.1157],\n",
       "         [-0.1225,  0.0926,  0.0005,  ..., -0.1555,  0.1885, -0.0947],\n",
       "         ...,\n",
       "         [-0.1211, -0.1031, -0.2189,  ..., -0.0425,  0.0308, -0.1494],\n",
       "         [-0.1388, -0.2042, -0.0915,  ..., -0.1358,  0.0989, -0.1457],\n",
       "         [-0.1299, -0.0490, -0.0078,  ..., -0.1410,  0.1205,  0.0703]],\n",
       "\n",
       "        [[-0.1288, -0.0181, -0.1728,  ...,  0.1026,  0.0010,  0.0820],\n",
       "         [-0.1275,  0.0761, -0.1723,  ..., -0.0505,  0.0866, -0.2194],\n",
       "         [-0.1281,  0.1392, -0.0290,  ..., -0.0633, -0.1486,  0.0842],\n",
       "         ...,\n",
       "         [-0.1194, -0.1203,  0.2193,  ...,  0.1725, -0.2985, -0.1448],\n",
       "         [-0.1383, -0.1579,  0.0026,  ..., -0.1164, -0.1716, -0.1073],\n",
       "         [-0.1237,  0.0375, -0.0494,  ...,  0.4008, -0.0798, -0.0275]],\n",
       "\n",
       "        [[-0.1311,  0.0038,  0.1746,  ..., -0.0586, -0.0234, -0.1496],\n",
       "         [-0.1245,  0.0207,  0.1359,  ...,  0.0480,  0.1597,  0.0769],\n",
       "         [-0.1276,  0.2131,  0.1001,  ...,  0.0255,  0.1467,  0.0474],\n",
       "         ...,\n",
       "         [-0.1219, -0.1265, -0.1870,  ..., -0.0284, -0.2327,  0.0633],\n",
       "         [-0.1393, -0.1998, -0.2081,  ...,  0.0094,  0.0246,  0.0345],\n",
       "         [-0.1180, -0.0341,  0.0257,  ...,  0.0767, -0.0308, -0.0658]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1311,  0.0966, -0.0901,  ..., -0.0531,  0.0098, -0.0375],\n",
       "         [-0.1296, -0.0517, -0.1657,  ...,  0.0421,  0.1423,  0.0590],\n",
       "         [-0.1243, -0.1557, -0.0806,  ..., -0.0201, -0.2081, -0.0242],\n",
       "         ...,\n",
       "         [-0.1190,  0.1512,  0.2004,  ..., -0.0555,  0.0294, -0.0621],\n",
       "         [-0.1355,  0.2018,  0.1251,  ...,  0.0059, -0.3182,  0.0087],\n",
       "         [-0.1301, -0.0036,  0.0640,  ..., -0.0395,  0.1584,  0.4067]],\n",
       "\n",
       "        [[-0.1308,  0.0490, -0.0868,  ...,  0.0339, -0.0025,  0.1068],\n",
       "         [-0.1325, -0.1289, -0.1899,  ...,  0.0706, -0.2349,  0.0589],\n",
       "         [-0.1290, -0.0699, -0.1428,  ...,  0.1576,  0.2661, -0.0248],\n",
       "         ...,\n",
       "         [-0.1205,  0.1547,  0.2125,  ...,  0.1648,  0.0575,  0.0546],\n",
       "         [-0.1339,  0.1469,  0.0773,  ..., -0.1400,  0.1525, -0.0891],\n",
       "         [-0.1227,  0.0422, -0.0217,  ...,  0.1747,  0.2151,  0.2537]],\n",
       "\n",
       "        [[-0.1323,  0.0219,  0.1779,  ..., -0.0385,  0.0644,  0.1222],\n",
       "         [-0.1230, -0.1505,  0.1680,  ..., -0.0808,  0.1223,  0.0420],\n",
       "         [-0.1280, -0.0866,  0.0592,  ..., -0.0739,  0.0992,  0.1601],\n",
       "         ...,\n",
       "         [-0.1185,  0.1580, -0.1415,  ...,  0.0714, -0.3868, -0.1150],\n",
       "         [-0.1466,  0.1151, -0.1160,  ...,  0.0566,  0.1108, -0.2682],\n",
       "         [-0.1217,  0.0755, -0.0497,  ..., -0.2174, -0.1281, -0.0307]]],\n",
       "       grad_fn=<LinalgSvdBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  \n",
    "    # Appendix G.2.3: SVD\n",
    "    U, S, V = torch.svd(model.EQKE)\n",
    "    print(torch.diag(S)[0]/torch.diag(S)[1])\n",
    "    U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0276a3-f582-4371-9bf2-e8ed0c6dc498",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), \"trained_transformer.pth\")\n",
    "\n",
    "    # Appendix B.2: Heatmaps\n",
    "    # Create a list to store the heatmap images\n",
    "    heatmap_images = []\n",
    "\n",
    "    # Generate heatmaps and store them in the list\n",
    "    heatmap_images.append(plot_heatmap(model.EQKE, \"EQKE (Position-Independent Attention)\", \"key token\", \"query token\"))\n",
    "    heatmap_images.append(plot_heatmap(model.EQKP, \"EQKP (Position-Dependent Attention)\", \"key position\", \"query token\"))\n",
    "    heatmap_images.append(plot_heatmap(model.EVOU, \"EVOU (Value Output)\", \"output logit token\", \"input token\"))\n",
    "    heatmap_images.append(plot_heatmap(model.PVOU, \"PVOU (Position-Dependent Output)\", \"output logit token\", \"input position\"))\n",
    "    heatmap_images.append(plot_heatmap(model.EU, \"EU (Direct Path)\", \"output logit token\", \"input token\"))\n",
    "\n",
    "    # Create a grid of images\n",
    "    num_cols = 2\n",
    "    num_rows = (len(heatmap_images) + 1) // 2  # Round up to ensure all images fit\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 10 * num_rows))\n",
    "\n",
    "    # Flatten the axes array for easier indexing\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Add each heatmap to the grid\n",
    "    for i, heatmap_fig in enumerate(heatmap_images):\n",
    "        heatmap_fig.canvas.draw()     \n",
    "        axes[i].imshow(heatmap_fig.canvas.buffer_rgba())\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    for i in range(len(heatmap_images), len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    # Adjust the layout and save the figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"heatmap_grid.png\")\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
